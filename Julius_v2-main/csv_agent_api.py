"""
API-–≤–µ—Ä—Å–∏—è CSV Analysis Agent –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏
Julius.ai style - –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—Ä–∞—Å–∏–≤—ã–º –≤—ã–≤–æ–¥–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—Ç –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–≥–æ CSV
"""

import os
import io
import json
import traceback
import gc
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import contextlib
import base64
from datetime import datetime

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from openai import OpenAI

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ Excel —Ñ–æ—Ä–º–∞—Ç–æ–≤
try:
    import openpyxl
    EXCEL_SUPPORT = True
    print("‚úì –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Excel (.xlsx, .xlsm): –í–∫–ª—é—á–µ–Ω–∞")
except ImportError:
    EXCEL_SUPPORT = False
    print("‚ö†Ô∏è openpyxl –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Excel –æ—Ç–∫–ª—é—á–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openpyxl")

try:
    import xlrd
    XLS_SUPPORT = True
    print("‚úì –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä—ã—Ö .xls —Ñ–∞–π–ª–æ–≤: –í–∫–ª—é—á–µ–Ω–∞")
except ImportError:
    XLS_SUPPORT = False
    print("‚ö†Ô∏è xlrd –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–æ–¥–¥–µ—Ä–∂–∫–∞ .xls —Ñ–∞–π–ª–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install xlrd")


# –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å - Claude Sonnet 4.5
MODEL_ID = "anthropic/claude-sonnet-4.5"
MODEL_NAME = "Claude Sonnet 4.5"


class CSVAnalysisAgentAPI:
    """
    API-–≤–µ—Ä—Å–∏—è –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è CSV —Ñ–∞–π–ª–æ–≤ (Julius.ai style)
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—Ç –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–≥–æ CSV
    """

    def __init__(self, api_key: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞

        Args:
            api_key: API –∫–ª—é—á –¥–ª—è OpenRouter
        """
        self.api_key = api_key

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenRouter
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key
        )

        self.model = MODEL_ID
        self.model_name = MODEL_NAME

        self.current_df = None
        self.original_df = None  # –•—Ä–∞–Ω–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        self.current_filename = None
        self.max_retries = 3

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –¥–∞–Ω–Ω—ã—Ö
        self.data_metadata = {
            "has_unnamed_columns": False,
            "first_row_is_header": False,
            "columns_cleaned": False,
            "rows_removed": 0,
            "cols_removed": 0,
            "was_edited": False
        }

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        sns.set_style("whitegrid")
        plt.rcParams['figure.figsize'] = (10, 6)
        plt.rcParams['figure.dpi'] = 100

    def _is_first_row_header(self, df: pd.DataFrame) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º

        –ö—Ä–∏—Ç–µ—Ä–∏–∏:
        1. –¢–µ–∫—É—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Ç–∏–ø–∞ "Unnamed: 0", "Unnamed: 1"...
        2. –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è)
        3. –í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Å–ª–æ–≤—ã–µ/—Å–º–µ—à–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–¥–∞–Ω–Ω—ã–µ)
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –ú–Ω–æ–≥–æ Unnamed –∫–æ–ª–æ–Ω–æ–∫?
        unnamed_count = sum(1 for col in df.columns if 'Unnamed' in str(col))
        if unnamed_count < len(df.columns) * 0.3:  # –ú–µ–Ω—å—à–µ 30% unnamed
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —Ç–µ–∫—Å—Ç?
        if len(df) < 2:
            return False

        first_row = df.iloc[0]
        second_row = df.iloc[1]

        # –°—á–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ
        text_count_row1 = sum(1 for val in first_row if isinstance(val, str) and not str(val).replace('.', '').replace('-', '').isdigit())

        # –°—á–∏—Ç–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–æ –≤—Ç–æ—Ä–æ–π —Å—Ç—Ä–æ–∫–µ
        numeric_count_row2 = sum(1 for val in second_row if pd.notna(val) and (isinstance(val, (int, float)) or str(val).replace('.', '').replace('-', '').isdigit()))

        # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —Ç–µ–∫—Å—Ç, –∞ –≤—Ç–æ—Ä–∞—è - —á–∏—Å–ª–∞
        return text_count_row1 > len(first_row) * 0.5 and numeric_count_row2 > len(second_row) * 0.3

    def _detect_separator(self, file_bytes: bytes) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å CSV —Ñ–∞–π–ª–∞
        """
        try:
            # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            sample = file_bytes[:8192].decode('utf-8', errors='ignore')
            lines = sample.split('\n')[:5]
            
            separators = [',', ';', '\t', '|']
            sep_counts = {}
            
            for sep in separators:
                counts = [line.count(sep) for line in lines if line.strip()]
                if counts:
                    # –ò—â–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤–æ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫–∞—Ö
                    if len(set(counts)) == 1 and counts[0] > 0:
                        sep_counts[sep] = counts[0]
                    elif counts:
                        sep_counts[sep] = max(counts)
            
            if sep_counts:
                return max(sep_counts, key=sep_counts.get)
            return ','
        except:
            return ','

    def _detect_encoding(self, file_bytes: bytes) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞
        """
        encodings = ['utf-8', 'utf-8-sig', 'cp1251', 'latin-1', 'iso-8859-1']
        
        for encoding in encodings:
            try:
                file_bytes.decode(encoding)
                return encoding
            except:
                continue
        
        return 'utf-8'

    def smart_load_file(self, file_bytes: bytes, filename: str = "data.csv") -> Dict[str, Any]:
        """
        –£–º–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV/Excel —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        –†–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ Julius.ai - —Å–Ω–∞—á–∞–ª–∞ –ø–æ–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø–æ—Ç–æ–º –æ—á–∏—â–∞–µ—Ç
        
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
        - CSV (.csv) - —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        - Excel (.xlsx, .xls, .xlsm) - —á–∏—Ç–∞–µ—Ç –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç

        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–∞–≥—Ä—É–∑–∫–µ –∏ –æ—á–∏—Å—Ç–∫–µ
        """
        load_info = {
            "filename": filename,
            "steps": [],
            "warnings": [],
            "original_shape": None,
            "final_shape": None,
            "success": True,
            "file_format": "csv"
        }

        self.current_filename = filename
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
        file_ext = os.path.splitext(filename)[1].lower()

        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
            if file_ext in ['.xlsx', '.xls', '.xlsm']:
                # Excel —Ñ–∞–π–ª
                load_info["file_format"] = "excel"
                load_info["steps"].append(f"üìä –û–ø—Ä–µ–¥–µ–ª—ë–Ω —Ñ–æ—Ä–º–∞—Ç: Excel ({file_ext})")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
                if file_ext == '.xls' and not XLS_SUPPORT:
                    raise Exception(
                        f"–§–æ—Ä–º–∞—Ç .xls –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. "
                        f"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É: pip install xlrd"
                    )
                if file_ext in ['.xlsx', '.xlsm'] and not EXCEL_SUPPORT:
                    raise Exception(
                        f"–§–æ—Ä–º–∞—Ç Excel –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. "
                        f"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É: pip install openpyxl"
                    )
                
                try:
                    # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç Excel —Ñ–∞–π–ª–∞
                    df_raw = pd.read_excel(io.BytesIO(file_bytes), sheet_name=0)
                    load_info["steps"].append("üì• –ó–∞–≥—Ä—É–∂–µ–Ω –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç Excel —Ñ–∞–π–ª–∞")
                except Exception as e:
                    raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Excel —Ñ–∞–π–ª–∞: {str(e)}. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω.")
            else:
                # CSV —Ñ–∞–π–ª
                load_info["file_format"] = "csv"
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∏ –∫–æ–¥–∏—Ä–æ–≤–∫—É
                sep = self._detect_separator(file_bytes)
                encoding = self._detect_encoding(file_bytes)
                
                load_info["steps"].append(f"üîç –û–ø—Ä–µ–¥–µ–ª—ë–Ω —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: '{sep}', –∫–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding}")

                # –ó–∞–≥—Ä—É–∂–∞–µ–º CSV "–∫–∞–∫ –µ—Å—Ç—å"
                df_raw = pd.read_csv(io.BytesIO(file_bytes), sep=sep, encoding=encoding, on_bad_lines='skip')
            
            self.original_df = df_raw.copy()
            load_info["original_shape"] = df_raw.shape
            load_info["steps"].append(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {df_raw.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df_raw.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")

            # –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä—è–µ–º "Unnamed" –∫–æ–ª–æ–Ω–∫–∏
            unnamed_cols = [col for col in df_raw.columns if 'Unnamed' in str(col)]
            if unnamed_cols:
                self.data_metadata["has_unnamed_columns"] = True
                load_info["warnings"].append(
                    f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(unnamed_cols)} –∫–æ–ª–æ–Ω–æ–∫ —Ç–∏–ø–∞ 'Unnamed'. "
                    f"–í–æ–∑–º–æ–∂–Ω–æ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏."
                )
                load_info["steps"].append(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(unnamed_cols)} –±–µ–∑—ã–º—è–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

            # –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É - –º–æ–∂–µ—Ç —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏?
            if self._is_first_row_header(df_raw):
                self.data_metadata["first_row_is_header"] = True
                load_info["steps"].append("üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ: –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö")

                # –î–µ–ª–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                new_columns = df_raw.iloc[0].tolist()
                df_raw.columns = new_columns
                df_raw = df_raw.iloc[1:].reset_index(drop=True)

                load_info["steps"].append("‚úÖ –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏")

            # –®–ê–ì 4: –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç –ø—Ä–æ–±–µ–ª–æ–≤
            original_cols = list(df_raw.columns)
            df_raw.columns = df_raw.columns.astype(str).str.strip()
            cleaned_cols = list(df_raw.columns)

            if original_cols != cleaned_cols:
                self.data_metadata["columns_cleaned"] = True
                load_info["steps"].append("üßπ –û—á–∏—â–µ–Ω—ã –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤")

            # –®–ê–ì 5: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            rows_before = len(df_raw)
            df_raw = df_raw.dropna(how='all')
            rows_after = len(df_raw)
            rows_removed = rows_before - rows_after

            if rows_removed > 0:
                self.data_metadata["rows_removed"] = rows_removed
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {rows_removed} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫")

            # –®–ê–ì 6: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            cols_before = len(df_raw.columns)
            df_raw = df_raw.dropna(axis=1, how='all')
            cols_after = len(df_raw.columns)
            cols_removed = cols_before - cols_after

            if cols_removed > 0:
                self.data_metadata["cols_removed"] = cols_removed
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {cols_removed} –ø—É—Å—Ç—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

            # –®–ê–ì 7: –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å —Ç–æ–ª—å–∫–æ NaN/–ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            # –∏ –∫–æ–ª–æ–Ω–∫–∏ —Ç–∏–ø–∞ "Unnamed" –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ
            cols_to_drop = []
            for col in df_raw.columns:
                if 'Unnamed' in str(col):
                    if df_raw[col].isna().all() or (df_raw[col].astype(str).str.strip() == '').all():
                        cols_to_drop.append(col)
            
            if cols_to_drop:
                df_raw = df_raw.drop(columns=cols_to_drop)
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(cols_to_drop)} –ø—É—Å—Ç—ã—Ö Unnamed –∫–æ–ª–æ–Ω–æ–∫")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.current_df = df_raw.reset_index(drop=True)

            load_info["final_shape"] = self.current_df.shape
            load_info["steps"].append(
                f"‚úÖ –ò—Ç–æ–≥–æ: {self.current_df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {self.current_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫"
            )

            return load_info

        except Exception as e:
            load_info["success"] = False
            load_info["error"] = str(e)
            raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV —Ñ–∞–π–ª–∞ '{filename}': {str(e)}")

    def load_csv_from_bytes(self, file_bytes: bytes, filename: str = "data.csv") -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV/Excel –∏–∑ –±–∞–π—Ç–æ–≤ (—Å —É–º–Ω–æ–π –æ—á–∏—Å—Ç–∫–æ–π)

        Args:
            file_bytes: –ë–∞–π—Ç—ã CSV –∏–ª–∏ Excel —Ñ–∞–π–ª–∞
            filename: –ò–º—è —Ñ–∞–π–ª–∞ (–≤–∞–∂–Ω–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞)

        Returns:
            DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        """
        self.smart_load_file(file_bytes, filename)
        return self.current_df
    
    # –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    def smart_load_csv(self, file_bytes: bytes, filename: str = "data.csv") -> Dict[str, Any]:
        """–ê–ª–∏–∞—Å –¥–ª—è smart_load_file (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
        return self.smart_load_file(file_bytes, filename)

    def load_csv_from_file(self, file_path: str) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV –∏–∑ –ø—É—Ç–∏ (–¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ - –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ø–∞–º—è—Ç—å)

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            DataFrame
        """
        filename = os.path.basename(file_path)
        self.current_filename = filename

        load_info = {
            "filename": filename,
            "steps": [],
            "warnings": [],
            "original_shape": None,
            "final_shape": None,
            "success": True,
            "file_format": "csv"
        }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
        file_ext = os.path.splitext(filename)[1].lower()

        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞ - –Ω–∞–ø—Ä—è–º—É—é —Å –¥–∏—Å–∫–∞!
            if file_ext in ['.xlsx', '.xls', '.xlsm']:
                load_info["file_format"] = "excel"
                load_info["steps"].append(f"üìä –û–ø—Ä–µ–¥–µ–ª—ë–Ω —Ñ–æ—Ä–º–∞—Ç: Excel ({file_ext})")

                if file_ext == '.xls' and not XLS_SUPPORT:
                    raise Exception(f"–§–æ—Ä–º–∞—Ç .xls –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install xlrd")
                if file_ext in ['.xlsx', '.xlsm'] and not EXCEL_SUPPORT:
                    raise Exception(f"–§–æ—Ä–º–∞—Ç Excel –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openpyxl")

                # –ß–∏—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é —Å –¥–∏—Å–∫–∞ (–Ω–µ —á–µ—Ä–µ–∑ BytesIO!)
                df_raw = pd.read_excel(file_path, sheet_name=0)
                load_info["steps"].append("üì• –ó–∞–≥—Ä—É–∂–µ–Ω –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç Excel —Ñ–∞–π–ª–∞ —Å –¥–∏—Å–∫–∞")
            else:
                # CSV —Ñ–∞–π–ª - —á–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ –±–∞–π—Ç—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                with open(file_path, 'rb') as f:
                    sample_bytes = f.read(8192)  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 8 –ö–ë –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

                sep = self._detect_separator(sample_bytes)
                encoding = self._detect_encoding(sample_bytes)

                load_info["steps"].append(f"üîç –û–ø—Ä–µ–¥–µ–ª—ë–Ω —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: '{sep}', –∫–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding}")

                # –ß–∏—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é —Å –¥–∏—Å–∫–∞ (–Ω–µ —á–µ—Ä–µ–∑ BytesIO!)
                df_raw = pd.read_csv(file_path, sep=sep, encoding=encoding, on_bad_lines='skip')

            # –ù–ï –î–ï–õ–ê–ï–ú –ö–û–ü–ò–Æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏!
            # self.original_df = df_raw.copy()  # –£–î–ê–õ–ï–ù–û - —ç–∫–æ–Ω–æ–º–∏—è ~77+ –ú–ë
            self.original_df = None  # –î–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ —Ö—Ä–∞–Ω–∏–º –∫–æ–ø–∏—é

            load_info["original_shape"] = df_raw.shape
            load_info["steps"].append(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {df_raw.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df_raw.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")

            # –û—Å—Ç–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞ smart_load_file
            unnamed_cols = [col for col in df_raw.columns if 'Unnamed' in str(col)]
            if unnamed_cols:
                self.data_metadata["has_unnamed_columns"] = True
                load_info["steps"].append(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(unnamed_cols)} –±–µ–∑—ã–º—è–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

            if self._is_first_row_header(df_raw):
                self.data_metadata["first_row_is_header"] = True
                load_info["steps"].append("üéØ –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≥–æ–ª–æ–≤–∫–∏, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º")
                new_columns = df_raw.iloc[0].tolist()
                df_raw.columns = new_columns
                df_raw = df_raw.iloc[1:].reset_index(drop=True)

            # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
            df_raw.columns = df_raw.columns.astype(str).str.strip()

            # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            rows_before = len(df_raw)
            df_raw = df_raw.dropna(how='all')
            rows_removed = rows_before - len(df_raw)
            if rows_removed > 0:
                self.data_metadata["rows_removed"] = rows_removed
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {rows_removed} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫")

            # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            cols_before = len(df_raw.columns)
            df_raw = df_raw.dropna(axis=1, how='all')
            cols_removed = cols_before - len(df_raw.columns)
            if cols_removed > 0:
                self.data_metadata["cols_removed"] = cols_removed
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {cols_removed} –ø—É—Å—Ç—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

            # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ Unnamed –∫–æ–ª–æ–Ω–∫–∏
            cols_to_drop = []
            for col in df_raw.columns:
                if 'Unnamed' in str(col):
                    if df_raw[col].isna().all() or (df_raw[col].astype(str).str.strip() == '').all():
                        cols_to_drop.append(col)
            if cols_to_drop:
                df_raw = df_raw.drop(columns=cols_to_drop)
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(cols_to_drop)} –ø—É—Å—Ç—ã—Ö Unnamed –∫–æ–ª–æ–Ω–æ–∫")

            self.current_df = df_raw.reset_index(drop=True)
            load_info["final_shape"] = self.current_df.shape
            load_info["steps"].append(f"‚úÖ –ò—Ç–æ–≥–æ: {self.current_df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {self.current_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")

            return self.current_df

        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ '{filename}': {str(e)}")

    def analyze_csv_schema(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã CSV —Ñ–∞–π–ª–∞

        Args:
            df: DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ö–µ–º–µ
        """
        schema = {
            "columns": list(df.columns),
            "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
            "shape": {"rows": int(df.shape[0]), "columns": int(df.shape[1])},
            "missing_values": {col: int(count) for col, count in df.isnull().sum().items()},
            "sample_data": df.head(5).to_dict(orient='records'),
            "summary_stats": {},
            "metadata": self.data_metadata
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            stats_df = df[numeric_cols].describe()
            schema["summary_stats"] = {
                col: {stat: float(val) for stat, val in stats_df[col].items()}
                for col in numeric_cols
            }

        return schema

    def get_deep_data_profile(self, df: pd.DataFrame) -> str:
        """
        –°–æ–∑–¥–∞—ë—Ç –≥–ª—É–±–æ–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ò–ò-–∞–≥–µ–Ω—Ç–∞.
        –ê–≥–µ–Ω—Ç –≤–∏–¥–∏—Ç –ø–æ–ª–Ω—É—é –∫–∞—Ä—Ç–∏–Ω—É –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –ø—Ä–∏–Ω—è—Ç–∏–µ–º —Ä–µ—à–µ–Ω–∏–π.
        
        Returns:
            –°—Ç—Ä–æ–∫–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö
        """
        profile_lines = []
        profile_lines.append("=" * 60)
        profile_lines.append("üìä –ì–õ–£–ë–û–ö–ò–ô –ü–†–û–§–ò–õ–¨ –î–ê–ù–ù–´–•")
        profile_lines.append("=" * 60)
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        total_cells = df.shape[0] * df.shape[1]
        total_missing = df.isna().sum().sum()
        fill_rate = ((total_cells - total_missing) / total_cells * 100) if total_cells > 0 else 0
        
        profile_lines.append(f"\nüìê –†–ê–ó–ú–ï–†: {df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
        profile_lines.append(f"üìà –ó–ê–ü–û–õ–ù–ï–ù–ù–û–°–¢–¨: {fill_rate:.1f}% ({total_cells - total_missing}/{total_cells} —è—á–µ–µ–∫)")
        profile_lines.append(f"‚ö†Ô∏è –í–°–ï–ì–û –ü–£–°–¢–´–• –Ø–ß–ï–ï–ö: {total_missing}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
        profile_lines.append(f"\n{'‚îÄ' * 60}")
        profile_lines.append("üìã –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ö–û–õ–û–ù–û–ö:")
        profile_lines.append(f"{'‚îÄ' * 60}")
        
        for col in df.columns:
            col_data = df[col]
            missing_count = col_data.isna().sum()
            missing_pct = (missing_count / len(df) * 100) if len(df) > 0 else 0
            non_null_count = col_data.notna().sum()
            unique_count = col_data.nunique()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ
            dtype = str(col_data.dtype)
            if dtype == 'object':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥–∞—Ç—ã
                sample_vals = col_data.dropna().head(10)
                is_date = False
                if len(sample_vals) > 0:
                    try:
                        pd.to_datetime(sample_vals, errors='raise')
                        is_date = True
                        dtype = "datetime (—Ç–µ–∫—Å—Ç)"
                    except:
                        pass
                if not is_date:
                    dtype = "text"
            elif 'int' in dtype or 'float' in dtype:
                dtype = "numeric"
            elif 'datetime' in dtype:
                dtype = "datetime"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–æ–Ω–∫–µ
            profile_lines.append(f"\n‚ñ∏ '{col}' [{dtype}]")
            
            if missing_count > 0:
                warning = "‚ö†Ô∏è" if missing_pct > 10 else "‚ÑπÔ∏è"
                profile_lines.append(f"  {warning} –ü—É—Å—Ç—ã—Ö: {missing_count} ({missing_pct:.1f}%)")
            else:
                profile_lines.append(f"  ‚úÖ –ü—É—Å—Ç—ã—Ö: 0 (–ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω–∞)")
            
            profile_lines.append(f"  üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {unique_count}")
            
            # –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π
            sample_vals = col_data.dropna().head(5).tolist()
            if sample_vals:
                sample_str = ", ".join([str(v)[:30] for v in sample_vals])
                profile_lines.append(f"  üìù –ü—Ä–∏–º–µ—Ä—ã: {sample_str}")
            
            # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            if 'numeric' in dtype and non_null_count > 0:
                try:
                    profile_lines.append(f"  üìà –ú–∏–Ω: {col_data.min():.2f}, –ú–∞–∫—Å: {col_data.max():.2f}, –°—Ä–µ–¥–Ω–µ–µ: {col_data.mean():.2f}")
                except:
                    pass
        
        # –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        profile_lines.append(f"\n{'‚îÄ' * 60}")
        profile_lines.append("üîç –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –û–°–û–ë–ï–ù–ù–û–°–¢–ò –î–ê–ù–ù–´–•:")
        profile_lines.append(f"{'‚îÄ' * 60}")
        
        problems_found = False
        
        # –ö–æ–ª–æ–Ω–∫–∏ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        for col in df.columns:
            missing_pct = (df[col].isna().sum() / len(df) * 100) if len(df) > 0 else 0
            if missing_pct > 0:
                problems_found = True
                if missing_pct > 50:
                    profile_lines.append(f"‚ö†Ô∏è '{col}' - {missing_pct:.1f}% –ø—É—Å—Ç—ã—Ö (–±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)")
                elif missing_pct > 10:
                    profile_lines.append(f"‚ÑπÔ∏è '{col}' - {missing_pct:.1f}% –ø—É—Å—Ç—ã—Ö")
                else:
                    profile_lines.append(f"üìå '{col}' - {df[col].isna().sum()} –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π ({missing_pct:.1f}%)")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
        dup_count = df.duplicated().sum()
        if dup_count > 0:
            problems_found = True
            profile_lines.append(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {dup_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å—Ç—Ä–æ–∫")
        
        if not problems_found:
            profile_lines.append("‚úÖ –î–∞–Ω–Ω—ã–µ –≤—ã–≥–ª—è–¥—è—Ç —á–∏—Å—Ç—ã–º–∏, —è–≤–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        
        # –ü—Ä–∏–º–µ—Ä—ã —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        rows_with_na = df[df.isna().any(axis=1)]
        if len(rows_with_na) > 0:
            profile_lines.append(f"\n{'‚îÄ' * 60}")
            profile_lines.append(f"üìã –ü–†–ò–ú–ï–†–´ –°–¢–†–û–ö –° –ü–£–°–¢–´–ú–ò –ó–ù–ê–ß–ï–ù–ò–Ø–ú–ò ({min(3, len(rows_with_na))} –∏–∑ {len(rows_with_na)}):")
            profile_lines.append(f"{'‚îÄ' * 60}")
            for idx, row in rows_with_na.head(3).iterrows():
                na_cols = [col for col in df.columns if pd.isna(row[col])]
                profile_lines.append(f"  –°—Ç—Ä–æ–∫–∞ {idx}: –ø—É—Å—Ç—ã–µ –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö [{', '.join(na_cols)}]")
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏
                non_na_vals = [(col, row[col]) for col in df.columns[:4] if pd.notna(row[col])]
                if non_na_vals:
                    vals_str = ", ".join([f"{col}={val}" for col, val in non_na_vals])
                    profile_lines.append(f"    –î–∞–Ω–Ω—ã–µ: {vals_str}...")
        
        # –ü—Ä–∏–º–µ—Ä—ã –ø–æ–ª–Ω—ã—Ö —Å—Ç—Ä–æ–∫ (–±–µ–∑ –ø—É—Å—Ç—ã—Ö)
        complete_rows = df.dropna()
        if len(complete_rows) > 0:
            profile_lines.append(f"\n{'‚îÄ' * 60}")
            profile_lines.append(f"‚úÖ –ü–†–ò–ú–ï–†–´ –ü–û–õ–ù–´–• –°–¢–†–û–ö (–±–µ–∑ –ø—É—Å—Ç—ã—Ö):")
            profile_lines.append(f"{'‚îÄ' * 60}")
            for idx, row in complete_rows.head(2).iterrows():
                vals = [(col, row[col]) for col in df.columns[:5]]
                vals_str = ", ".join([f"{col}={val}" for col, val in vals])
                profile_lines.append(f"  –°—Ç—Ä–æ–∫–∞ {idx}: {vals_str}...")
        
        profile_lines.append(f"\n{'=' * 60}")
        
        return "\n".join(profile_lines)

    def df_to_csv_base64(self, df: pd.DataFrame = None) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å DataFrame –≤ base64 CSV
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å ';' –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Windows Excel
        (–≤ –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏—Ö/—Ä—É—Å—Å–∫–∏—Ö –ª–æ–∫–∞–ª—è—Ö Excel –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–∂–∏–¥–∞–µ—Ç ';')

        Args:
            df: DataFrame –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é current_df)

        Returns:
            Base64 —Å—Ç—Ä–æ–∫–∞ CSV —Ñ–∞–π–ª–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ';'
        """
        if df is None:
            df = self.current_df
        
        if df is None:
            return None
        
        csv_buffer = io.StringIO()
        # sep=';' –¥–ª—è Windows Excel, encoding='utf-8-sig' –¥–æ–±–∞–≤–ª—è–µ—Ç BOM –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig', sep=';')
        csv_bytes = csv_buffer.getvalue().encode('utf-8-sig')
        return base64.b64encode(csv_bytes).decode('utf-8')

    def execute_python_code(self, code: str, df: pd.DataFrame) -> Tuple[bool, Any, str, List[str], Optional[pd.DataFrame]]:
        """
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Python –∫–æ–¥–∞ —Å –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ base64
        –∏ –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–≥–æ DataFrame

        Args:
            code: Python –∫–æ–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            df: DataFrame –¥–ª—è —Ä–∞–±–æ—Ç—ã

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—É—Å–ø–µ—Ö, —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –≤—ã–≤–æ–¥/–æ—à–∏–±–∫–∞, —Å–ø–∏—Å–æ–∫ base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–π DataFrame)
        """
        local_vars = {
            'df': df.copy(),
            'pd': pd,
            'np': np,
            'plt': plt,
            'sns': sns,
            'result': None,
            'modified_df': None  # –î–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–≥–æ DataFrame
        }

        stdout_capture = io.StringIO()
        stderr_capture = io.StringIO()
        plot_base64_list = []
        modified_df = None

        try:
            with contextlib.redirect_stdout(stdout_capture), \
                 contextlib.redirect_stderr(stderr_capture):

                # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–¥
                exec(code, local_vars)

                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                result = local_vars.get('result', None)
                output = stdout_capture.getvalue()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –∏–∑–º–µ–Ω—ë–Ω DataFrame
                modified_df = local_vars.get('modified_df', None)
                
                # –ï—Å–ª–∏ modified_df –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —è–≤–Ω–æ, –Ω–æ df –±—ã–ª –∏–∑–º–µ–Ω—ë–Ω
                if modified_df is None and 'df' in local_vars:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ df
                    current_df = local_vars['df']
                    if not current_df.equals(df):
                        modified_df = current_df

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON-serializable —Ñ–æ—Ä–º–∞—Ç
                if isinstance(result, (np.integer, np.floating)):
                    result = float(result)
                elif isinstance(result, np.ndarray):
                    result = result.tolist()
                elif isinstance(result, pd.DataFrame) or isinstance(result, pd.Series):
                    result = str(result)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –≤ base64
                if plt.get_fignums():
                    for fig_num in plt.get_fignums():
                        fig = plt.figure(fig_num)

                        buffer = io.BytesIO()
                        fig.savefig(buffer, format='png', bbox_inches='tight', dpi=150)
                        buffer.seek(0)

                        img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
                        plot_base64_list.append(f"data:image/png;base64,{img_base64}")

                        buffer.close()

                    plt.close('all')

                return True, result, output, plot_base64_list, modified_df

        except Exception as e:
            error_msg = f"{type(e).__name__}: {str(e)}\n{traceback.format_exc()}"
            return False, None, error_msg, [], None
        finally:
            plt.close('all')
            plt.clf()
            local_vars.clear()

    def auto_clean_data(self) -> Dict[str, Any]:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–æ–≥–¥–∞ –∑–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª, –Ω–æ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—á–∏—Å—Ç–∫–∏ —Å –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–º CSV
        """
        if self.current_df is None:
            return {
                "success": False,
                "error": "CSV —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
            }
        
        df = self.current_df.copy()
        cleaning_steps = []
        original_shape = df.shape
        
        # –®–ê–ì 1: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        rows_to_skip = 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫
        for i in range(min(5, len(df))):
            row = df.iloc[i]
            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–≥–æ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π - –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –º—É—Å–æ—Ä
            nan_count = row.isna().sum()
            if nan_count > len(row) * 0.8:  # –ë–æ–ª–µ–µ 80% –ø—É—Å—Ç—ã—Ö
                rows_to_skip = i + 1
                cleaning_steps.append(f"üóëÔ∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ #{i+1}")
        
        if rows_to_skip > 0:
            df = df.iloc[rows_to_skip:].reset_index(drop=True)
            cleaning_steps.append(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {rows_to_skip} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –≤ –Ω–∞—á–∞–ª–µ")
        
        # –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ - –º–æ–∂–µ—Ç —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏?
        if len(df) > 1:
            first_row = df.iloc[0]
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–∞ –ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            string_count = sum(1 for val in first_row if isinstance(val, str) and len(str(val).strip()) > 0)
            
            # –ï—Å–ª–∏ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ - Unnamed –∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç
            unnamed_count = sum(1 for col in df.columns if 'Unnamed' in str(col))
            
            if unnamed_count > len(df.columns) * 0.5 and string_count > len(first_row) * 0.3:
                # –î–µ–ª–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
                new_columns = [str(val).strip() if pd.notna(val) else f'Column_{i}' 
                              for i, val in enumerate(first_row)]
                df.columns = new_columns
                df = df.iloc[1:].reset_index(drop=True)
                cleaning_steps.append("üéØ –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏")
        
        # –®–ê–ì 3: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        empty_cols = [col for col in df.columns 
                     if df[col].isna().all() or (df[col].astype(str).str.strip() == '').all()]
        if empty_cols:
            df = df.drop(columns=empty_cols)
            cleaning_steps.append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(empty_cols)} –ø—É—Å—Ç—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")
        
        # –®–ê–ì 4: –£–¥–∞–ª—è–µ–º Unnamed –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –ø—É—Å—Ç—ã–µ –∏–ª–∏ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏
        unnamed_to_drop = []
        for col in df.columns:
            if 'Unnamed' in str(col):
                col_values = df[col].dropna()
                # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ –ø—É—Å—Ç–∞—è –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–∞ (–≤–æ–∑–º–æ–∂–Ω–æ –∏–Ω–¥–µ–∫—Å—ã)
                if len(col_values) == 0:
                    unnamed_to_drop.append(col)
                else:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–∞ (–∏–Ω–¥–µ–∫—Å—ã)?
                    try:
                        numeric_values = pd.to_numeric(col_values, errors='coerce')
                        if numeric_values.notna().all():
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                            if (numeric_values.diff().dropna() == 1).all():
                                unnamed_to_drop.append(col)
                    except:
                        pass
        
        if unnamed_to_drop:
            df = df.drop(columns=unnamed_to_drop)
            cleaning_steps.append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(unnamed_to_drop)} —Å–ª—É–∂–µ–±–Ω—ã—Ö Unnamed –∫–æ–ª–æ–Ω–æ–∫")
        
        # –®–ê–ì 5: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        rows_before = len(df)
        df = df.dropna(how='all')
        rows_removed = rows_before - len(df)
        if rows_removed > 0:
            cleaning_steps.append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {rows_removed} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫")
        
        # –®–ê–ì 6: –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
        df.columns = [str(col).strip() for col in df.columns]
        
        # –®–ê–ì 7: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        for col in df.columns:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–∞
            try:
                numeric_col = pd.to_numeric(df[col], errors='coerce')
                if numeric_col.notna().sum() > len(df) * 0.5:  # –ë–æ–ª–µ–µ 50% —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ
                    df[col] = numeric_col
            except:
                pass
            
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –¥–∞—Ç—ã
            if df[col].dtype == 'object':
                try:
                    date_col = pd.to_datetime(df[col], errors='coerce', infer_datetime_format=True)
                    if date_col.notna().sum() > len(df) * 0.5:
                        df[col] = date_col
                        cleaning_steps.append(f"üìÖ –ö–æ–ª–æ–Ω–∫–∞ '{col}' –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –¥–∞—Ç—ã")
                except:
                    pass
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π DataFrame
        df = df.reset_index(drop=True)
        self.current_df = df
        self.data_metadata["was_edited"] = True
        
        final_shape = df.shape
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        summary = f"""## üßπ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- **–§–∞–π–ª:** {self.current_filename}
- **–†–∞–∑–º–µ—Ä:** {original_shape[0]} —Å—Ç—Ä–æ–∫ √ó {original_shape[1]} –∫–æ–ª–æ–Ω–æ–∫

### ‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —à–∞–≥–∏ –æ—á–∏—Å—Ç–∫–∏
"""
        for step in cleaning_steps:
            summary += f"- {step}\n"
        
        if not cleaning_steps:
            summary += "- –î–∞–Ω–Ω—ã–µ —É–∂–µ —á–∏—Å—Ç—ã–µ, –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è\n"
        
        summary += f"""
### üìà –†–µ–∑—É–ª—å—Ç–∞—Ç
- **–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:** {final_shape[0]} —Å—Ç—Ä–æ–∫ √ó {final_shape[1]} –∫–æ–ª–æ–Ω–æ–∫
- **–ö–æ–ª–æ–Ω–∫–∏:** {', '.join(df.columns.tolist())}

### üìã –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""
        # –î–æ–±–∞–≤–ª—è–µ–º preview —Ç–∞–±–ª–∏—Ü—ã
        preview_df = df.head(5)
        summary += self._df_to_markdown(preview_df)
        
        summary += """

–¢–∞–±–ª–∏—Ü–∞ –æ—á–∏—â–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∞–Ω–∞–ª–∏–∑—É! 
–í—ã –º–æ–∂–µ—Ç–µ:
- –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ –¥–∞–Ω–Ω—ã—Ö
- –ü–æ–ø—Ä–æ—Å–∏—Ç—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫
- –ó–∞–ø—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
- –ü–æ–ø—Ä–æ—Å–∏—Ç—å –∏–∑–º–µ–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ (–¥–æ–±–∞–≤–∏—Ç—å/—É–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ —Å—Ç–æ–ª–±—Ü—ã)
"""
        
        return {
            "success": True,
            "query": "[–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞]",
            "code_attempts": [],
            "final_code": "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö",
            "result_data": None,
            "text_output": summary,
            "plots": [],
            "error": None,
            "attempts_count": 1,
            "timestamp": datetime.utcnow().isoformat(),
            "load_info": self.data_metadata,
            "modified_csv": self.df_to_csv_base64(df),
            "was_modified": True,
            "cleaning_steps": cleaning_steps
        }
    
    def _df_to_markdown(self, df: pd.DataFrame, max_rows: int = 10) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å DataFrame –≤ Markdown —Ç–∞–±–ª–∏—Ü—É
        """
        if df is None or len(df) == 0:
            return "*(–ø—É—Å—Ç–∞—è —Ç–∞–±–ª–∏—Ü–∞)*"
        
        display_df = df.head(max_rows)
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        headers = list(display_df.columns)
        md = "| " + " | ".join(str(h) for h in headers) + " |\n"
        md += "|" + "|".join(["---"] * len(headers)) + "|\n"
        
        # –°—Ç—Ä–æ–∫–∏
        for _, row in display_df.iterrows():
            values = []
            for val in row:
                if pd.isna(val):
                    values.append("")
                elif isinstance(val, float):
                    values.append(f"{val:,.2f}")
                else:
                    values.append(str(val))
            md += "| " + " | ".join(values) + " |\n"
        
        if len(df) > max_rows:
            md += f"\n*...–∏ –µ—â—ë {len(df) - max_rows} —Å—Ç—Ä–æ–∫*\n"
        
        return md

    def generate_code_with_retry(self, user_query: str, schema: Dict,
                                 chat_history: List[Dict] = None,
                                 previous_error: Optional[str] = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Python –∫–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é AI (Julius.ai style - –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–π –ø–æ–¥—Ö–æ–¥)
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            schema: –°—Ö–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö CSV
            chat_history: –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            previous_error: –ü—Ä–µ–¥—ã–¥—É—â–∞—è –æ—à–∏–±–∫–∞ (–¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏)

        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Python –∫–æ–¥
        """
        system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö, —Ä–∞–±–æ—Ç–∞—é—â–∏–π –∫–∞–∫ Julius.ai.

üß† –ì–õ–ê–í–ù–û–ï –ü–†–ê–í–ò–õ–û: –°–ù–ê–ß–ê–õ–ê –î–£–ú–ê–ô, –ü–û–¢–û–ú –î–ï–ô–°–¢–í–£–ô!

–ü–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º –õ–Æ–ë–û–ì–û –∑–∞–ø—Ä–æ—Å–∞ —Ç—ã –û–ë–Ø–ó–ê–ù:
1. –ò–ó–£–ß–ò–¢–¨ –¥–∞–Ω–Ω—ã–µ (—Å–º–æ—Ç—Ä–∏ –ø—Ä–æ—Ñ–∏–ª—å –¥–∞–Ω–Ω—ã—Ö –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ)
2. –ü–û–ù–Ø–¢–¨ —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ö–æ—á–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
3. –ü–†–û–í–ï–†–ò–¢–¨ –µ—Å—Ç—å –ª–∏ –Ω—É–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–∫–æ–ª–æ–Ω–∫–∏
4. –í–´–ü–û–õ–ù–ò–¢–¨ –∑–∞–¥–∞—á—É —Å —É—á—ë—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìã –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –ö–û–î–ê:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

```python
# === –®–ê–ì 1: –ò–ó–£–ß–ï–ù–ò–ï –î–ê–ù–ù–´–• ===
print("üîç –®–ê–ì 1: –ò–∑—É—á–∞—é –¥–∞–Ω–Ω—ã–µ...")
print(f"–†–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")

# –í–°–ï–ì–î–ê –ø—Ä–æ–≤–µ—Ä—è–π –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ü–ï–†–ï–î –ª—é–±–æ–π –æ–ø–µ—Ä–∞—Ü–∏–µ–π!
missing_info = df.isna().sum()
cols_with_missing = missing_info[missing_info > 0]
if len(cols_with_missing) > 0:
    print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
    for col, count in cols_with_missing.items():
        print(f"   ‚Ä¢ {col}: {count} –ø—É—Å—Ç—ã—Ö ({count/len(df)*100:.1f}%)")
else:
    print("‚úÖ –ü—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç")

# –°—Ç—Ä–æ–∫–∏ —Å –ª—é–±—ã–º–∏ –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
rows_with_na = df[df.isna().any(axis=1)]
print(f"üìä –°—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏: {len(rows_with_na)} –∏–∑ {len(df)}")

# === –®–ê–ì 2: –ü–û–ù–ò–ú–ê–ù–ò–ï –ó–ê–ü–†–û–°–ê ===
print("\\nüéØ –®–ê–ì 2: –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è...")
# –û–±—ä—è—Å–Ω–∏ —á—Ç–æ –ø–æ–Ω—è–ª –∏–∑ –∑–∞–ø—Ä–æ—Å–∞

# === –®–ê–ì 3: –í–´–ü–û–õ–ù–ï–ù–ò–ï ===
print("\\n‚öôÔ∏è –®–ê–ì 3: –í—ã–ø–æ–ª–Ω—è—é...")

# –î–ª—è –†–ï–î–ê–ö–¢–ò–†–û–í–ê–ù–ò–Ø –¥–∞–Ω–Ω—ã—Ö:
# df = df.dropna()  # –£–¥–∞–ª–∏—Ç—å –í–°–ï —Å—Ç—Ä–æ–∫–∏ —Å –ª—é–±—ã–º–∏ –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
# df = df.dropna(subset=['col1', 'col2'])  # –£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
# df = df.drop(columns=['col'])  # –£–¥–∞–ª–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É
# df['new'] = ...  # –î–æ–±–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É
# df = df[df['col'] > 100]  # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è

# –í–ê–ñ–ù–û! –ü–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö:
# modified_df = df.copy()

# === –®–ê–ì 4: –†–ï–ó–£–õ–¨–¢–ê–¢ ===
print("\\n‚úÖ –®–ê–ì 4: –ì–æ—Ç–æ–≤–æ!")

result = f\"\"\"
## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç

–û–ø–∏—Å–∞–Ω–∏–µ —á—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ...

| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | –ó–Ω–∞—á–µ–Ω–∏–µ |
|------------|----------|
| –î–æ | {before} |
| –ü–æ—Å–ª–µ | {after} |
\"\"\"

# –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω—ã - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
# modified_df = df.copy()
```

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üîß –¢–ò–ü–ò–ß–ù–´–ï –û–ü–ï–†–ê–¶–ò–ò –° –î–ê–ù–ù–´–ú–ò:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìå –£–î–ê–õ–ï–ù–ò–ï –°–¢–†–û–ö –° –ü–£–°–¢–´–ú–ò –ó–ù–ê–ß–ï–ù–ò–Ø–ú–ò:
```python
# –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
rows_before = len(df)
rows_with_na = df[df.isna().any(axis=1)]
print(f"–°—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏: {len(rows_with_na)}")

# –£–¥–∞–ª–∏—Ç—å –í–°–ï —Å—Ç—Ä–æ–∫–∏ –≥–¥–µ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
df = df.dropna()

# –ò–õ–ò —É–¥–∞–ª–∏—Ç—å —Ç–æ–ª—å–∫–æ –≥–¥–µ –ø—É—Å—Ç—ã–µ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
# df = df.dropna(subset=['Column1', 'Column2'])

rows_after = len(df)
print(f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫: {rows_before - rows_after}")
modified_df = df.copy()
```

üìå –£–î–ê–õ–ï–ù–ò–ï –ö–û–õ–û–ù–û–ö:
```python
df = df.drop(columns=['Column_Name'])
modified_df = df.copy()
```

üìå –§–ò–õ–¨–¢–†–ê–¶–ò–Ø:
```python
df = df[df['Column'] > 100]
df = df[df['Column'].notna()]  # –¢–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ
modified_df = df.copy()
```

üìå –ó–ê–ü–û–õ–ù–ï–ù–ò–ï –ü–£–°–¢–´–•:
```python
df['Column'] = df['Column'].fillna(0)  # –ó–∞–ø–æ–ª–Ω–∏—Ç—å –Ω—É–ª—è–º–∏
df['Column'] = df['Column'].fillna(df['Column'].mean())  # –°—Ä–µ–¥–Ω–∏–º
modified_df = df.copy()
```

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. **–í–°–ï–ì–î–ê –ü–†–û–í–ï–†–Ø–ô df.isna().sum()** –ø–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º –æ –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö!

2. **–ò–°–ü–û–õ–¨–ó–£–ô –î–ê–ù–ù–´–ï –ò–ó –ü–†–û–§–ò–õ–Ø** - —Ç–∞–º —É–∂–µ –µ—Å—Ç—å –≤—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö

3. **–ù–ï –û–¢–í–ï–ß–ê–ô "–ø—É—Å—Ç—ã—Ö –Ω–µ—Ç"** –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–≤–µ—Ä–∏–ª! –°–º–æ—Ç—Ä–∏ –ø—Ä–æ—Ñ–∏–ª—å –¥–∞–Ω–Ω—ã—Ö!

4. **modified_df = df.copy()** - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø–æ—Å–ª–µ –ª—é–±–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è!

5. **–õ–û–ì–ò–†–£–ô –í–°–Å** —á–µ—Ä–µ–∑ print() - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω –≤–∏–¥–µ—Ç—å –∫–∞–∂–¥—ã–π —à–∞–≥

6. **–§–û–†–ú–ê–¢–ò–†–£–ô –ß–ò–°–õ–ê**: {value:,.0f} –∏–ª–∏ {value:,.2f}

7. **result = —Å—Ç—Ä–æ–∫–∞ —Å Markdown** - –∑–∞–≥–æ–ª–æ–≤–∫–∏ ##, —Ç–∞–±–ª–∏—Ü—ã, —ç–º–æ–¥–∑–∏

8. **–ì–ò–ë–ö–ò–ô –ü–û–ò–°–ö –ö–û–õ–û–ù–û–ö** - –∏—â–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º, –Ω–µ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
"""

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –≥–ª—É–±–æ–∫–∏–º –ø—Ä–æ—Ñ–∏–ª–µ–º
        deep_profile = self.get_deep_data_profile(self.current_df)
        
        column_details = []
        for col in schema['columns']:
            dtype = schema['dtypes'][col]
            missing = schema['missing_values'].get(col, 0)

            examples = []
            if len(schema['sample_data']) > 0:
                for row in schema['sample_data'][:3]:
                    val = row.get(col)
                    if pd.notna(val):
                        examples.append(str(val))

            examples_str = ", ".join(examples[:3]) if examples else "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

            col_info = f"  ‚Ä¢ '{col}' ({dtype})"
            if missing > 0:
                col_info += f" [‚ö†Ô∏è –ø—É—Å—Ç—ã—Ö: {missing}]"
            col_info += f"\n    –ü—Ä–∏–º–µ—Ä—ã: {examples_str}"
            column_details.append(col_info)

        user_message = f"""
{deep_profile}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üéØ –ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_query}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö° –ù–ê–ü–û–ú–ò–ù–ê–ù–ò–ï:
- –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏ –ü–†–û–§–ò–õ–¨ –î–ê–ù–ù–´–• –≤—ã—à–µ!
- –¢–∞–º —É–∫–∞–∑–∞–Ω—ã –í–°–ï –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–µ!
- –°–ù–ê–ß–ê–õ–ê –ø—Ä–æ–≤–µ—Ä—å –¥–∞–Ω–Ω—ã–µ, –ü–û–¢–û–ú –¥–µ–π—Å—Ç–≤—É–π!
- –ï—Å–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ—à—å –¥–∞–Ω–Ω—ã–µ - —É—Å—Ç–∞–Ω–æ–≤–∏ modified_df = df.copy()
"""

        if self.data_metadata.get("first_row_is_header"):
            user_message += "\n\n‚úÖ –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ CSV –±—ã–ª–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏."

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
        if chat_history and len(chat_history) > 0:
            history_text = "\n\n–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:\n"
            for i, item in enumerate(chat_history[-5:], 1):
                history_text += f"\n{i}. –ó–∞–ø—Ä–æ—Å: {item.get('query', '')}\n"
                if item.get('success'):
                    history_text += f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {item.get('text_output', '')[:200]}\n"
            user_message += history_text

        if previous_error:
            user_message += f"""

–ü–†–ï–î–´–î–£–©–ê–Ø –ü–û–ü–´–¢–ö–ê –ó–ê–í–ï–†–®–ò–õ–ê–°–¨ –û–®–ò–ë–ö–û–ô:
{previous_error}

–ò—Å–ø—Ä–∞–≤—å –∫–æ–¥, —É—á–∏—Ç—ã–≤–∞—è —ç—Ç—É –æ—à–∏–±–∫—É.
"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.2,
                max_tokens=4000
            )

            code = response.choices[0].message.content.strip()

            # –£–±–∏—Ä–∞–µ–º markdown —Ä–∞–∑–º–µ—Ç–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
            if code.startswith("```python"):
                code = code[9:]
            if code.startswith("```"):
                code = code[3:]
            if code.endswith("```"):
                code = code[:-3]

            return code.strip()

        except Exception as e:
            error_msg = str(e)

            if "401" in error_msg or "Unauthorized" in error_msg or "User not found" in error_msg:
                raise Exception(
                    f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ OpenRouter (401): API –∫–ª—é—á –Ω–µ–≤–µ—Ä–Ω—ã–π –∏–ª–∏ –∏—Å—Ç–µ–∫. "
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ OPENROUTER_API_KEY –≤ .env —Ñ–∞–π–ª–µ. "
                    f"–ü–æ–ª—É—á–∏—Ç–µ –Ω–æ–≤—ã–π –∫–ª—é—á –Ω–∞ https://openrouter.ai/keys. "
                    f"–î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            elif "403" in error_msg:
                raise Exception(
                    f"–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω (403): –£ API –∫–ª—é—á–∞ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥–µ–ª–∏ {self.model} "
                    f"–∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤. –î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            elif "429" in error_msg:
                raise Exception(
                    f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (429): –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API. "
                    f"–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞. –î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            else:
                raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞: {error_msg}")

    def analyze(self, user_query: str = None, chat_history: List[Dict] = None) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è API
        –ï—Å–ª–∏ user_query –ø—É—Å—Ç–æ–π - –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ—á–∏—Å—Ç–∫—É

        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ –ø—É—Å—Ç–æ–π - –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞)
            chat_history: –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ API
        """
        if self.current_df is None:
            return {
                "success": False,
                "error": "CSV —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω",
                "timestamp": datetime.utcnow().isoformat()
            }

        # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø—É—Å—Ç–æ–π –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞
        if not user_query or user_query.strip() == "":
            return self.auto_clean_data()

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ö–µ–º—É –¥–∞–Ω–Ω—ã—Ö
        schema = self.analyze_csv_schema(self.current_df)

        result = {
            "success": False,
            "query": user_query,
            "code_attempts": [],
            "final_code": None,
            "result_data": None,
            "text_output": None,
            "plots": [],
            "error": None,
            "attempts_count": 0,
            "timestamp": datetime.utcnow().isoformat(),
            "load_info": self.data_metadata,
            "modified_csv": None,
            "was_modified": False
        }

        previous_error = None

        for attempt in range(self.max_retries):
            result["attempts_count"] = attempt + 1

            try:
                code = self.generate_code_with_retry(
                    user_query,
                    schema,
                    chat_history,
                    previous_error
                )

                result["code_attempts"].append({
                    "attempt": attempt + 1,
                    "code": code,
                    "success": False
                })

            except Exception as e:
                result["error"] = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞: {str(e)}"
                break

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–¥
            success, exec_result, output, plot_base64_list, modified_df = self.execute_python_code(
                code, self.current_df
            )

            if success:
                result["success"] = True
                result["final_code"] = code
                result["result_data"] = exec_result
                result["text_output"] = output
                result["plots"] = plot_base64_list
                result["code_attempts"][-1]["success"] = True
                
                # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω—ã
                if modified_df is not None:
                    self.current_df = modified_df
                    self.data_metadata["was_edited"] = True
                    result["modified_csv"] = self.df_to_csv_base64(modified_df)
                    result["was_modified"] = True
                
                break
            else:
                previous_error = output
                result["code_attempts"][-1]["error"] = output

                if attempt == self.max_retries - 1:
                    result["error"] = f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–¥ –ø–æ—Å–ª–µ {self.max_retries} –ø–æ–ø—ã—Ç–æ–∫"
                    result["error_details"] = output

        return result

    def get_schema_info(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º CSV —Ñ–∞–π–ª–µ

        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ö–µ–º–µ –¥–∞–Ω–Ω—ã—Ö
        """
        if self.current_df is None:
            return {
                "success": False,
                "error": "CSV —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
            }

        schema = self.analyze_csv_schema(self.current_df)
        return {
            "success": True,
            "schema": schema,
            "timestamp": datetime.utcnow().isoformat()
        }

    def get_current_csv(self) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π CSV –≤ base64

        Returns:
            Base64 —Å—Ç—Ä–æ–∫–∞ CSV –∏–ª–∏ None
        """
        return self.df_to_csv_base64()

    def cleanup(self):
        """
        –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞
        """
        if self.current_df is not None:
            del self.current_df
            self.current_df = None

        if self.original_df is not None:
            del self.original_df
            self.original_df = None

        plt.close('all')
        gc.collect()
