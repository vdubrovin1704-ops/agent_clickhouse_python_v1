"""
–ì–ª–∞–≤–Ω—ã–π –∞–≥–µ–Ω—Ç: ClickHouse ‚Üí Parquet ‚Üí Python Analysis.
–†–µ–∞–ª–∏–∑—É–µ—Ç –∞–≥–µ–Ω—Ç–Ω—ã–π —Ü–∏–∫–ª —á–µ—Ä–µ–∑ Anthropic Messages API —Å native tool_use.
"""

import json
import time
import traceback
import uuid
from pathlib import Path

import anthropic

from config import ANTHROPIC_API_KEY, MODEL, MAX_TOKENS, TEMP_DIR
from clickhouse_client import ClickHouseClient
from python_sandbox import PythonSandbox
from chat_storage import ChatStorage
from tools import TOOLS_LIST


SYSTEM_PROMPT = """–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö ClickHouse –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é Python.

## –¢–≤–æ–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å:

### –®–∞–≥ 1: –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –û–ø—Ä–µ–¥–µ–ª–∏:
- –ö–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω—É–∂–Ω—ã?
- –ù—É–∂–Ω–∞ –ª–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–≥—Ä–∞—Ñ–∏–∫)?
- –ù—É–∂–Ω–∞ –ª–∏ —Ç–∞–±–ª–∏—Ü–∞?
- –ù—É–∂–Ω—ã –ª–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è/–∞–≥—Ä–µ–≥–∞—Ü–∏–∏?

### –®–∞–≥ 2: –ò–∑—É—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
–ï—Å–ª–∏ —Ç—ã –µ—â—ë –ù–ï –∑–Ω–∞–µ—à—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü (–ø–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –≤ —Å–µ—Å—Å–∏–∏) ‚Äî –≤—ã–∑–æ–≤–∏ `list_tables`.
–ï—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —É–∂–µ –∏–∑–≤–µ—Å—Ç–Ω–∞ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞ ‚Äî –ø—Ä–æ–ø—É—Å—Ç–∏ —ç—Ç–æ—Ç —à–∞–≥.

### –®–∞–≥ 3: –í—ã–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ ClickHouse
–ù–∞–ø–∏—à–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π SQL –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ `clickhouse_query`:
- –î–µ–ª–∞–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (SUM, COUNT, AVG, GROUP BY) –í –°–ê–ú–û–ú SQL ‚Äî —ç—Ç–æ –±—ã—Å—Ç—Ä–µ–µ
- –§–∏–ª—å—Ç—Ä—É–π –¥–∞–Ω–Ω—ã–µ –≤ WHERE ‚Äî –Ω–µ –≤—ã–≥—Ä—É–∂–∞–π –ª–∏—à–Ω–µ–µ
- –î–æ–±–∞–≤–ª—è–π LIMIT (–æ–±—ã—á–Ω–æ 1000-10000 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, –¥–æ 50000 –¥–ª—è –±–æ–ª—å—à–∏—Ö –≤—ã–±–æ—Ä–æ–∫)
- –ò—Å–ø–æ–ª—å–∑—É–π ClickHouse —Ñ—É–Ω–∫—Ü–∏–∏: toStartOfMonth(), toYear(), arrayJoin(), –∏ —Ç.–¥.

### –®–∞–≥ 4: –ê–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ Python
–í—ã–∑–æ–≤–∏ `python_analysis` –¥–ª—è:
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ (bar, line, pie, scatter, heatmap)
- –°–æ–∑–¥–∞–Ω–∏—è –∫—Ä–∞—Å–∏–≤—ã—Ö —Ç–∞–±–ª–∏—Ü
- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (–ø—Ä–æ—Ü–µ–Ω—Ç—ã, —Ä–∞–Ω–≥–∏, —Ç—Ä–µ–Ω–¥—ã)

### –ü—Ä–∞–≤–∏–ª–∞ Python-–∫–æ–¥–∞:
1. –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è `df` —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç DataFrame ‚Äî –ù–ï –≤—ã–∑—ã–≤–∞–π pd.read_parquet()
2. –í–°–ï–ì–î–ê —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π `result` ‚Äî —Å—Ç—Ä–æ–∫—É —Å Markdown –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞
3. –ò—Å–ø–æ–ª—å–∑—É–π print() –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: print("üìä –®–∞–≥ 1: –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ...")
4. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π –≥—Ä–∞—Ñ–∏–∫–∏: plt.title(), plt.xlabel(), plt.ylabel() ‚Äî –Ω–∞ —Ä—É—Å—Å–∫–æ–º
5. –§–æ—Ä–º–∞—Ç–∏—Ä—É–π —á–∏—Å–ª–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏: f"{value:,.0f}"
6. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤ result –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã: üìä üìà ‚úÖ üìã

### –®–∞–≥ 5: –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
–°—Ñ–æ—Ä–º–∏—Ä—É–π –ø–æ–Ω—è—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç —Å –≤—ã–≤–æ–¥–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏.
–ù–ï –¥—É–±–ª–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ result ‚Äî –æ–Ω–∏ —É–∂–µ –ø–æ–∫–∞–∑–∞–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
–î–æ–±–∞–≤—å –∫—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é.

## –°—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞:
- –ò—Å–ø–æ–ª—å–∑—É–π Markdown: –∑–∞–≥–æ–ª–æ–≤–∫–∏ ##, —Ç–∞–±–ª–∏—Ü—ã, —Å–ø–∏—Å–∫–∏
- –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
- –ß–∏—Å–ª–∞ ‚Äî —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ —Ç—ã—Å—è—á
- –Ø–∑—ã–∫ ‚Äî —Ä—É—Å—Å–∫–∏–π
"""


class CompositeAnalysisAgent:
    """
    –ê–≥–µ–Ω—Ç, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π ClickHouse-–∑–∞–ø—Ä–æ—Å—ã –∏ Python-–∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Anthropic Messages API —Å native tool_use.
    """

    def __init__(self):
        self.anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        self.ch_client = ClickHouseClient()
        self.sandbox = PythonSandbox()
        self.chat_storage = ChatStorage(
            db_path=str(Path(__file__).parent / "chat_history.db")
        )

    def analyze(self, user_query: str, session_id: str | None = None) -> dict:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

        Args:
            user_query: —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            session_id: ID —Å–µ—Å—Å–∏–∏ (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω)

        Returns:
            dict —Å –ø–æ–ª—è–º–∏:
              success, session_id, text_output, plots, tool_calls, error
        """
        if not session_id:
            session_id = str(uuid.uuid4())

        # Sanitize input ‚Äî –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç UTF-8 encoding errors –≤ Anthropic API
        user_query = user_query.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.chat_storage.save_user_message(session_id, user_query)

        # –ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∏–∑ SQLite ‚Üí —Ñ–æ—Ä–º–∞—Ç messages –¥–ª—è Anthropic API
        history = self.chat_storage.get_history(session_id)
        messages = [{"role": m["role"], "content": m["content"]} for m in history]

        all_plots = []       # –í—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ –≤—Å–µ—Ö –≤—ã–∑–æ–≤–æ–≤ python_analysis
        tool_calls_log = []  # –õ–æ–≥ –≤—ã–∑–æ–≤–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        max_iterations = 10  # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞

        for iteration in range(max_iterations):
            # –í—ã–∑–æ–≤ Claude
            response = self.anthropic_client.messages.create(
                model=MODEL,
                max_tokens=MAX_TOKENS,
                system=SYSTEM_PROMPT,
                tools=TOOLS_LIST,
                messages=messages,
            )

            # Claude –∑–∞–∫–æ–Ω—á–∏–ª ‚Äî —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            if response.stop_reason == "end_turn":
                text_parts = [
                    block.text
                    for block in response.content
                    if block.type == "text"
                ]
                final_text = "\n".join(text_parts)

                self.chat_storage.save_assistant_message(session_id, final_text)

                return {
                    "success": True,
                    "session_id": session_id,
                    "text_output": final_text,
                    "plots": all_plots,
                    "tool_calls": tool_calls_log,
                    "error": None,
                }

            # Claude —Ö–æ—á–µ—Ç –≤—ã–∑–≤–∞—Ç—å tool
            elif response.stop_reason == "tool_use":
                # –î–æ–±–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ messages (—Å tool_use –±–ª–æ–∫–∞–º–∏)
                assistant_content = []
                for block in response.content:
                    if block.type == "text":
                        assistant_content.append({"type": "text", "text": block.text})
                    elif block.type == "tool_use":
                        assistant_content.append({
                            "type": "tool_use",
                            "id": block.id,
                            "name": block.name,
                            "input": block.input,
                        })

                messages.append({"role": "assistant", "content": assistant_content})

                # –í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–∞–∂–¥—ã–π tool –∏ —Å–æ–±—Ä–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                tool_results_content = []

                for block in response.content:
                    if block.type != "tool_use":
                        continue

                    tool_result = self._execute_tool(block.name, block.input)

                    # Sanitize ‚Äî –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç encoding errors
                    tool_result = tool_result.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')

                    # –ï—Å–ª–∏ python_analysis ‚Äî –≤—ã–Ω–µ—Å—Ç–∏ –≥—Ä–∞—Ñ–∏–∫–∏ –∏–∑ tool_result
                    # —á—Ç–æ–±—ã base64 –Ω–µ —Ä–∞–∑–¥—É–≤–∞–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç Claude
                    if block.name == "python_analysis":
                        try:
                            result_data = json.loads(tool_result)
                            if result_data.get("plots"):
                                all_plots.extend(result_data["plots"])
                                result_data_for_claude = {
                                    k: v for k, v in result_data.items() if k != "plots"
                                }
                                result_data_for_claude["plots_count"] = len(result_data["plots"])
                                tool_result = json.dumps(result_data_for_claude, ensure_ascii=False, default=str)
                        except Exception:
                            pass

                    tool_calls_log.append({
                        "tool": block.name,
                        "input": block.input,
                        "iteration": iteration,
                    })

                    tool_results_content.append({
                        "type": "tool_result",
                        "tool_use_id": block.id,
                        "content": tool_result,
                    })

                messages.append({"role": "user", "content": tool_results_content})

            else:
                return {
                    "success": False,
                    "session_id": session_id,
                    "text_output": "",
                    "plots": [],
                    "tool_calls": tool_calls_log,
                    "error": f"Unexpected stop_reason: {response.stop_reason}",
                }

        # –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∏—Ç–µ—Ä–∞—Ü–∏–π
        return {
            "success": False,
            "session_id": session_id,
            "text_output": "",
            "plots": all_plots,
            "tool_calls": tool_calls_log,
            "error": "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∏—Ç–µ—Ä–∞—Ü–∏–π –∞–≥–µ–Ω—Ç–∞ (10)",
        }

    def _execute_tool(self, tool_name: str, tool_input: dict) -> str:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å tool –∏ –≤–µ—Ä–Ω—É—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ JSON-—Å—Ç—Ä–æ–∫—É."""
        try:
            if tool_name == "list_tables":
                return self.ch_client.list_tables()

            elif tool_name == "clickhouse_query":
                return self.ch_client.execute_query(tool_input["sql"])

            elif tool_name == "python_analysis":
                result = self.sandbox.execute(
                    code=tool_input["code"],
                    parquet_path=tool_input["parquet_path"],
                )
                # sandbox.execute() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict ‚Äî —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –≤ JSON
                return json.dumps(result, ensure_ascii=False, default=str)

            else:
                return json.dumps({"error": f"Unknown tool: {tool_name}"})

        except Exception as e:
            return json.dumps({
                "error": str(e),
                "traceback": traceback.format_exc(),
            })

    def cleanup_temp_files(self):
        """–£–¥–∞–ª–∏—Ç—å parquet —Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞."""
        cutoff = time.time() - 3600
        for f in TEMP_DIR.glob("*.parquet"):
            try:
                if f.stat().st_mtime < cutoff:
                    f.unlink()
            except Exception:
                pass
